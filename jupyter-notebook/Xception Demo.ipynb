{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168c08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers,Model\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout,InputLayer,Flatten,Dense,BatchNormalization,MaxPooling2D,Conv2D,Input,Concatenate,LeakyReLU\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical,normalize\n",
    "from keras.applications.xception import Xception,preprocess_input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "import keras.backend as K\n",
    "import random\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a86198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading already preprocessed files.\n",
    "x_train=joblib.load('D:\\\\Py files\\\\AAA - Thesis Codes\\\\packages\\\\T\\\\x_train.pkl')\n",
    "x_cv=joblib.load('D:\\\\Py files\\\\AAA - Thesis Codes\\\\packages\\\\T\\\\x_cv.pkl')\n",
    "x_test=joblib.load('D:\\\\Py files\\\\AAA - Thesis Codes\\\\packages\\\\T\\\\x_test.pkl')\n",
    "\n",
    "y_train=joblib.load('D:\\\\Py files\\\\AAA - Thesis Codes\\\\packages\\\\T\\\\y_train.pkl')\n",
    "y_cv=joblib.load('D:\\\\Py files\\\\AAA - Thesis Codes\\\\packages\\\\T\\\\y_cv.pkl')\n",
    "y_test=joblib.load('D:\\\\Py files\\\\AAA - Thesis Codes\\\\packages\\\\T\\\\y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7c7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train data (6840, 299, 299, 3)\n",
      "Shape of Cv data (450, 299, 299, 3)\n",
      "Shape of Test data (1800, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train data {}\".format(x_train.shape))\n",
    "print(\"Shape of Cv data {}\".format(x_cv.shape))\n",
    "print(\"Shape of Test data {}\".format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5803a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "Y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3b24f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train data (6840, 2)\n",
      "Shape of Cv data (450, 2)\n",
      "Shape of Test data (1800, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train data {}\".format(Y_train.shape))\n",
    "print(\"Shape of Cv data {}\".format(Y_cv.shape))\n",
    "print(\"Shape of Test data {}\".format(Y_test.shape))\n",
    "print(type(x_train))\n",
    "print(type(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873f6a21",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1492/1515505747.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m           metrics=['accuracy'])\n\u001b[1;32m---> 24\u001b[1;33m pretraining_Xception =model_pretrain.fit(x_train, Y_train,\n\u001b[0m\u001b[0;32m     25\u001b[0m                                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                                               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda installation\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda installation\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "#Greedy Layer-Wise Pretraining Learned from : https://machinelearningmastery.com/greedy-layer-wise-pretraining-tutorial/\n",
    "# 1. Pre-training the network with train data on initilizing the \"imagenet\" weights with \"include_top=False\"\n",
    "# 2. After training 3 epochs remove the top most layer\n",
    "# 3. Now add similar top layer and again train and validate\n",
    "\n",
    "\n",
    "Xception_initial=Xception(include_top=False,\n",
    "                 weights='imagenet',\n",
    "                 input_shape=(299,299,3),pooling ='avg',\n",
    "                 )\n",
    "#print(Xception_pre_trained.summary())\n",
    "\n",
    "for layer in Xception_initial.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "x = Xception_initial.output\n",
    "predicted = Dense(2,activation ='softmax')(x)\n",
    "model_pretrain = Model(inputs = Xception_initial.input, outputs = predicted)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "model_pretrain.compile(loss=keras.losses.categorical_crossentropy,\n",
    "          optimizer=opt,\n",
    "          metrics=['accuracy'])\n",
    "pretraining_Xception =model_pretrain.fit(x_train, Y_train,\n",
    "                                              verbose=1,\n",
    "                                              batch_size=32,  \n",
    "                                              epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4351bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
